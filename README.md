# ğŸš€ ETL Pipeline Using Docker, MySQL, and PostgreSQL

This project implements an **ETL (Extract, Transform, Load) pipeline** using **Dockerized MySQL and PostgreSQL** containers. The pipeline extracts data from MySQL, transforms it in a Node.js backend, and loads it into PostgreSQL.

## ğŸ“Œ Features
- **Extract** data from a MySQL database.
- **Transform** the extracted data (e.g., capitalize names).
- **Load** transformed data into a PostgreSQL database.
- **Dockerized environment** for seamless deployment.
- **Automated data initialization** using `init.sql`.

---

## ğŸ—ï¸ **Project Architecture**
1. **MySQL Database** - Stores raw data (initialized using `init.sql`).
2. **Node.js Backend (Express.js)** - Handles API routes for extraction, transformation, and loading.
3. **PostgreSQL Database** - Stores the cleaned and transformed data.
4. **Docker Compose** - Manages the containers for MySQL, PostgreSQL, and the backend service.

---

## âš™ï¸ **Setup Instructions**

### **ğŸ”¹ Prerequisites**
Ensure you have the following installed:
- [Docker & Docker Compose](https://docs.docker.com/get-docker/)
- [Git](https://git-scm.com/)
- [Node.js & npm](https://nodejs.org/)

### **ğŸ”¹ Clone the Repository**
```bash
git clone https://github.com/dinkleva/etl_project.git
cd etl_project


ğŸ›¢ MySQL: employee_data

id	name	department	salary
1	alice	HR	50000
2	bob	    IT	60000

ğŸ›¢ PostgreSQL: cleaned_data

id	name	department	salary
1	Alice	HR	50000
2	Bob	    IT	60000

ğŸš€ Enhancements & Future Work
âœ… Automate data validation before loading.
âœ… Implement logging and error handling.
âœ… Optimize database queries for performance.
âœ… Deploy on a cloud platform (e.g., AWS, GCP).


ğŸ† Author
ğŸ‘¤ dinkleva
ğŸ’¼ Passionate about data engineering & backend development!